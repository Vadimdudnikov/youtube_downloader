"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å WhisperX —á–µ—Ä–µ–∑ API –º–µ—Ç–æ–¥—ã
"""

import os
import json
import tempfile
import subprocess
from pathlib import Path
from app.config import settings
import whisperx
import torch

import warnings

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", message=".*torchaudio._backend.list_audio_backends.*")
warnings.filterwarnings("ignore", message=".*TensorFloat-32.*")
warnings.filterwarnings("ignore", message=".*whisperx.*")
warnings.filterwarnings("ignore", message=".*Lightning automatically upgraded.*")
warnings.filterwarnings("ignore", module="pytorch_lightning")
warnings.filterwarnings("ignore", module="speechbrain")
warnings.filterwarnings("ignore", module="transformers")


class WhisperXService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å WhisperX —á–µ—Ä–µ–∑ API –º–µ—Ç–æ–¥—ã"""

    # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫—ç—à –¥–ª—è –º–æ–¥–µ–ª–µ–π whisperx
    _models_cache = {}
    _align_models_cache = {}

    def __init__(self, model_size: str = None, device: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ WhisperX
        
        Args:
            model_size: –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (tiny, base, small, medium, large). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cuda –∏–ª–∏ cpu). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        """
        self.model_size = model_size or settings.whisperx_model
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.compute_type = "float16" if self.device == "cuda" else "int8"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self.model = self._load_model()
        
        if self.device == "cuda":
            print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º GPU: {torch.cuda.get_device_name(0)}")
            print(f"CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
            print(f"Compute type: {self.compute_type} (FP16)")
            torch.backends.cudnn.benchmark = True
        else:
            print("GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
            print(f"Compute type: {self.compute_type} (int8)")

    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å WhisperX —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = f"{self.model_size}_{self.device}_{self.compute_type}"
        
        if cache_key not in self._models_cache:
            print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å whisperx: {self.model_size} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")
            model = whisperx.load_model(
                self.model_size,
                device=self.device,
                compute_type=self.compute_type
            )
            self._models_cache[cache_key] = model
            print(f"‚úÖ –ú–æ–¥–µ–ª—å whisperx –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–∞")
        else:
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å whisperx: {self.model_size} –Ω–∞ {self.device}")
            model = self._models_cache[cache_key]
        
        return model

    def _load_align_model(self, language_code: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = f"align_{language_code}_{self.device}"
        
        if cache_key not in self._align_models_cache:
            print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è —è–∑—ã–∫–∞: {language_code}")
            align_model, metadata = whisperx.load_align_model(
                language_code=language_code,
                device=self.device
            )
            self._align_models_cache[cache_key] = (align_model, metadata)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–∞")
        else:
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è —è–∑—ã–∫–∞: {language_code}")
            align_model, metadata = self._align_models_cache[cache_key]
        
        return align_model, metadata

    def transcribe_audio(self, audio_path: str):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ
        –ü—Ä–∏–Ω–∏–º–∞–µ—Ç audio_path –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
        """
        print(f"üé§ –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ: {audio_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = self.check_file_size(audio_path)
        print(f"  –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:.1f} –ú–ë")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
        if file_size < 0.1:  # –ú–µ–Ω—å—à–µ 100KB
            raise ValueError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª ({file_size:.1f} –ú–ë). –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç")

        if self.needs_chunking(file_size):
            print("  ‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏...")
            segments = self._transcribe_large_audio(audio_path)
        else:
            print("  ‚úÖ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–¥–∏–Ω —Ñ–∞–π–ª")
            segments = self._transcribe_single_audio(audio_path)

        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        return segments

    def _transcribe_single_audio(self, audio_path: str):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω –∞—É–¥–∏–æ—Ñ–∞–π–ª"""
        print(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Ñ–∞–π–ª: {audio_path}")

        segments = self.transcribe_file(audio_path)

        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        return segments

    def _transcribe_large_audio(self, audio_path: str):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –±–æ–ª—å—à–æ–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –ø–æ —á–∞—Å—Ç—è–º"""
        print(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª –ø–æ —á–∞—Å—Ç—è–º: {audio_path}")

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–¥–∏–æ
        try:
            from pydub import AudioSegment
        except ImportError:
            raise ImportError("pydub –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pydub")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        file_ext = os.path.splitext(audio_path)[1].lower()
        if file_ext == '.mp3':
            audio = AudioSegment.from_mp3(audio_path)
        elif file_ext == '.wav':
            audio = AudioSegment.from_wav(audio_path)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
            audio = AudioSegment.from_file(audio_path)
        
        total_duration = len(audio) / 1000.0  # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–µ–∫—É–Ω–¥—ã

        chunk_duration = settings.chunk_duration_minutes * 60  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        all_segments = []
        time_offset = 0

        for i in range(0, int(total_duration), int(chunk_duration)):
            start_time = i
            end_time = min(i + chunk_duration, total_duration)

            # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —á–∞–Ω–∫ –∞—É–¥–∏–æ
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_chunk:
                chunk_path = temp_chunk.name

            cmd_chunk = [
                "ffmpeg", "-y", "-i", audio_path,
                "-ss", str(start_time), "-t", str(end_time - start_time),
                "-c", "copy", chunk_path
            ]
            subprocess.run(cmd_chunk, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            print(f"  –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫ {i//int(chunk_duration) + 1}...")

            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —á–∞–Ω–∫
            segments = self.transcribe_file(chunk_path, time_offset)

            all_segments.extend(segments)
            time_offset += chunk_duration

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —á–∞–Ω–∫
            if os.path.exists(chunk_path):
                os.remove(chunk_path)

        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(all_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        return all_segments

    def transcribe_file(self, audio_path: str, time_offset: float = 0):
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é WhisperX API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            time_offset: –°–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —á–∞–Ω–∫–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–∏ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤)
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
        """
        print(f"üé§ WhisperX: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º {os.path.basename(audio_path)}")
        print(f"  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        audio = whisperx.load_audio(audio_path)

        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ
        print("üîß –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é...")
        result = self.model.transcribe(audio, batch_size=16)

        detected_language = result.get("language", "unknown")
        print(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –Ø–∑—ã–∫: {detected_language}")

        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        print("–í—ã–ø–æ–ª–Ω—è–µ–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")
        align_model, metadata = self._load_align_model(language_code=detected_language)

        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å align_sentences=True
        result = whisperx.align(
            result["segments"],
            align_model,
            metadata,
            audio,
            self.device,
            return_char_alignments=False,
            align_sentences=True
        )

        print("‚úÖ –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        segments = self.process_segments(result, time_offset)

        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        return segments

    def process_segments(self, result: dict, time_offset: float = 0):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ WhisperX –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ç–∏—à–∏–Ω—ã
        
        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç whisperx.align() (—Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–æ–º "segments")
            time_offset: –°–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —á–∞–Ω–∫–æ–≤
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        print(f"üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã...")

        try:
            raw_segments = result.get("segments", [])
            print(f"  - –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ —Ñ–∞–π–ª–µ: {len(raw_segments)}")

            if len(raw_segments) == 0:
                print(f"‚ö†Ô∏è WhisperX –Ω–µ –Ω–∞—à–µ–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ –∞—É–¥–∏–æ —Ñ–∞–π–ª–µ")
                print(f"  –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
                print(f"  - –ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º —Ç–∏—Ö–æ–µ")
                print(f"  - –¢–æ–ª—å–∫–æ —Ñ–æ–Ω–æ–≤—ã–π —à—É–º –±–µ–∑ —Ä–µ—á–∏")
                print(f"  - –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª")
                print(f"  - –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ")
                return []

            segments = []
            empty_segments = 0

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º (–±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–∏—à–∏–Ω—ã)
            for i, segment in enumerate(raw_segments):
                text = segment.get("text", "").strip()
                if text:
                    segment_dict = {
                        "start": round(segment.get("start", 0) + time_offset, 3),
                        "end": round(segment.get("end", 0) + time_offset, 3),
                        "text": text
                    }
                    segments.append(segment_dict)
                else:
                    empty_segments += 1
                    if i < 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—É—Å—Ç—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                        print(f"  - –°–µ–≥–º–µ–Ω—Ç {i+1}: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç '{segment.get('text', '')}'")

            if empty_segments > 0:
                print(f"  - –ü—É—Å—Ç—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {empty_segments}")

            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –≥–æ–ª–æ—Å–æ–º (–±–µ–∑ —Ç–∏—à–∏–Ω—ã)")
            return segments

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")
            raise

    def check_file_size(self, audio_path: str) -> float:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë
        
        Args:
            audio_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            float: –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë
        """
        file_size = os.path.getsize(audio_path) / (1024 * 1024)  # –≤ –ú–ë
        return file_size

    def needs_chunking(self, file_size: float) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —Ä–∞–∑–±–∏–≤–∞—Ç—å —Ñ–∞–π–ª –Ω–∞ —á–∞—Å—Ç–∏
        
        Args:
            file_size: –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë
            
        Returns:
            bool: True –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω—É–∂–Ω–æ —Ä–∞–∑–±–∏–≤–∞—Ç—å –Ω–∞ —á–∞—Å—Ç–∏
        """
        # WhisperX –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã, –Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
        return file_size > 100  # 100 –ú–ë

